# === General settings ===
headless: true                  # Ejecutar emulación sin mostrar pantalla
debug: false                    # Mostrar información de depuración por consola
server: false                   # Modo servidor para control remoto (por ejemplo con sockets)
load_checkpoint: ""
notes: "Investigación de rendimiento con franja al 75, nuevo metodo de segmentacion + nuevo batch de entrenamiento"
root_dir: "game&results/Pokemon_red_env/checkpoints"

# === Emulación y entorno ===
emulation_speed: 6              # Velocidad de emulación (1 = tiempo real, >1 = acelerado)
action_freq: 24                 # Cada cuántos frames se aplica una acción
init_state: "game&results/Pokemon_red_env/STELLE.state"  # Estado inicial para reset
gb_path: "game&results/Pokemon_red_env/PokemonRed.gb"    # Ruta al archivo del juego

# === Observación y codificación ===
actions_stack: 32               # Tamaño del stack de acciones anteriores
coords_pad: 12                  # Padding aplicado a las coordenadas codificadas

# === Recompensas y exploración ===
reward_scale: 1               # Escala de recompensa base
explore_weight: 0.25            # Peso relativo de la recompensa por explorar
step_discount: 0.00001

# === Entrenamiento ===
num_cpu: 8                       # Número de entornos paralelos (subprocesos)
checkpoint_save_freq: 10000       # Frecuencia para guardar modelo (en pasos)
max_steps: 409600                 # Número máximo de pasos por iteración
train_steps_batch: 512
bach_size: 256
reward_threshold: -1

# === Logging & sesiones ===
print_rewards: false            # Mostrar recompensas en consola durante entrenamiento
save_video: false               # Guardar video de episodios
progress_bar: false
save_stats_every: 1

# === WandB (Weights & Biases) ===
use_wandb: false                 # Habilitar tracking con WandB
wandb_project: pokemon-train    # Nombre del proyecto WandB

